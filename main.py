import os
import tempfile
import logging
import cv2
import numpy as np
import openai
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
)

# ====== åŸºæœ¬è¨­å®š ======
BOT_TOKEN = os.environ["BOT_TOKEN"]
WEBHOOK_URL = os.environ["WEBHOOK_URL"]
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
log = logging.getLogger("bot")

# ====== å°å·¥å…· ======
def _analyze_to_columns(image_path: str, cell_size=30):
    img = cv2.imread(image_path)
    if img is None:
        raise RuntimeError("è®€ä¸åˆ°åœ–ç‰‡ï¼ˆå¯èƒ½è·¯å¾‘éŒ¯æˆ–æª”æ¡ˆå£æ‰ï¼‰")
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    lower_red1 = np.array([0, 100, 100]); upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 100, 100]); upper_red2 = np.array([179, 255, 255])
    lower_blue  = np.array([100, 150, 0]); upper_blue  = np.array([140, 255, 255])
    lower_green = np.array([40, 40, 40]); upper_green = np.array([90, 255, 255])

    red_mask   = cv2.inRange(hsv, lower_red1, upper_red1) + cv2.inRange(hsv, lower_red2, upper_red2)
    blue_mask  = cv2.inRange(hsv, lower_blue, upper_blue)
    green_mask = cv2.inRange(hsv, lower_green, upper_green)

    def contours(mask):
        cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
        return [cv2.boundingRect(c) for c in cnts]

    points = []
    for (x,y,w,h) in contours(red_mask):
        points.append(("èŠ", x//cell_size, y//cell_size))
    for (x,y,w,h) in contours(blue_mask):
        points.append(("é–’", x//cell_size, y//cell_size))
    for (x,y,w,h) in contours(green_mask):
        points.append(("å’Œ", x//cell_size, y//cell_size))

    if not points:
        return []

    max_col = max(p[1] for p in points) + 1
    max_row = max(p[2] for p in points) + 1
    grid = [["" for _ in range(max_col)] for _ in range(max_row)]
    for label, col, row in points:
        grid[row][col] = label

    columns = []
    for c in range(max_col):
        col_vals = [grid[r][c] for r in range(max_row) if grid[r][c]]
        if col_vals:
            columns.append(col_vals)
    return columns

def _generate_road(columns, offset):
    road = []
    for c in range(offset, len(columns)):
        if len(columns[c]) == len(columns[c - offset]):
            road.append("ç´…")
        else:
            road.append("è—")
    return road

def _generate_all_roads(columns):
    return {
        "å¤§çœ¼ä»”": _generate_road(columns, 1),
        "å°è·¯": _generate_road(columns, 2),
        "èŸ‘è‚è·¯": _generate_road(columns, 3),
    }

def _summarize_for_gpt(columns, roads):
    lines = ["ä¸»è·¯ï¼š"]
    for col in columns:
        lines.append("".join(col))
    lines.append("")
    lines.append("å‰¯è·¯çµ±è¨ˆï¼š")
    for name, r in roads.items():
        lines.append(f"{name}ï¼š{''.join(r)}")
    return "\n".join(lines)

def _fallback_brief(columns):
    flat = [x for col in columns for x in col if x in ("èŠ","é–’")]
    b = flat.count("èŠ")
    p = flat.count("é–’")
    total = max(1, b+p)
    b_rate = round(b/total*100,1)
    p_rate = round(p/total*100,1)
    # ç°¡å–®å»¶çºŒ
    pred = flat[-1] if flat else "æœªçŸ¥"
    return f"âœ… é æ¸¬ï¼š{pred}\nğŸ“Š å‹ç‡ï¼šèŠ {b_rate}%ã€é–’ {p_rate}%\nğŸ§  çµ±åˆåˆ†æï¼šç³»çµ±å‚™æ´ï¼ˆGPT æœªå›è¦†ï¼‰ï¼Œä»¥æœ€è¿‘è¶¨å‹¢èˆ‡ç¸½é«”æ¯”ä¾‹å›è¦†ã€‚"

def _gpt_predict(columns, roads):
    if not OPENAI_API_KEY:
        return None, "æœªè¨­å®š OPENAI_API_KEYï¼Œè·³é GPT"

    prompt = (
        "ä½ æ˜¯ç™¾å®¶æ¨‚é æ¸¬å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹ç‰Œè·¯ï¼Œåˆ†æä¸‹ä¸€å±€å¯èƒ½é–‹å‡ºã€èŠã€æˆ–ã€é–’ã€ï¼Œä¸¦è¼¸å‡ºä»¥ä¸‹æ ¼å¼ï¼š\n\n"
        "âœ… é æ¸¬ï¼šèŠ æˆ– é–’\n"
        "ğŸ“Š å‹ç‡ï¼šèŠ X%ã€é–’ Y%\n"
        "ğŸ§  çµ±åˆåˆ†æï¼šæ ¹æ“šç›®å‰èµ°å‹¢èˆ‡å‰¯è·¯è¶¨å‹¢ï¼Œé€²è¡Œç­–ç•¥åˆ¤æ–·èˆ‡èªªæ˜ã€‚\n\n"
        f"{_summarize_for_gpt(columns, roads)}"
    )
    try:
        resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role":"user","content":prompt}],
            temperature=0.7,
        )
        return resp.choices[0].message.content.strip(), None
    except Exception as e:
        return None, str(e)

# ====== Handlers ======
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ä½ å¥½ï¼Œæˆ‘æ˜¯ç™¾å®¶æ¨‚é æ¸¬æ©Ÿå™¨äººï¼è«‹å‚³ç‰Œè·¯åœ–ç‰‡ï¼ˆç…§ç‰‡æˆ–æª”æ¡ˆï¼‰çµ¦æˆ‘åˆ†æã€‚\nä¹Ÿå¯å…ˆ /ping æ¸¬è©¦æˆ‘æ˜¯å¦åœ¨ç·šã€‚")

async def ping(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ“ pongï¼ˆwebhook æ­£å¸¸ï¼‰")

async def echo_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # è®“ä½ ç¢ºèª webhook æœ‰æ²’æœ‰åˆ°é” handler
    txt = (update.message.text or "").strip()
    log.info(f"æ”¶åˆ°æ–‡å­—è¨Šæ¯ï¼š{txt}")
    await update.message.reply_text("æˆ‘åœ¨ï¼Œè«‹å‚³åœ–ç‰‡ï¼ˆæˆ–ç”¨ /ping æ¸¬è©¦ï¼‰")

async def _process_image_bytes(update: Update, image_bytes: bytes):
    await update.message.reply_text("ğŸ“¸ åœ–ç‰‡å·²æ¥æ”¶ï¼Œé–‹å§‹åˆ†æâ€¦")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as f:
        f.write(image_bytes)
        temp_path = f.name
    try:
        columns = _analyze_to_columns(temp_path)
        if not columns:
            await update.message.reply_text("âš ï¸ è®€ä¸åˆ°ç‰Œè·¯åœ–æ¡ˆï¼Œè«‹æ›ä¸€å¼µæ›´æ¸…æ™°çš„åœ–ç‰‡æˆ–è£æ‰å¤šé¤˜é‚Šæ¡†ã€‚")
            return
        roads = _generate_all_roads(columns)
        gpt_text, err = _gpt_predict(columns, roads)
        if gpt_text:
            await update.message.reply_text(gpt_text)
        else:
            log.warning(f"GPT å¤±æ•—æˆ–æœªè¨­å®šï¼š{err}")
            await update.message.reply_text(_fallback_brief(columns))
    except Exception as e:
        log.exception("è™•ç†åœ–ç‰‡å¤±æ•—")
        await update.message.reply_text(f"âš ï¸ åˆ†æéŒ¯èª¤ï¼š{e}")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        photo = update.message.photo[-1]
        file = await photo.get_file()
        b = await file.download_as_bytearray()
        await _process_image_bytes(update, b)
    except Exception as e:
        log.exception("è™•ç† photo å¤±æ•—")
        await update.message.reply_text(f"âš ï¸ è®€å–ç…§ç‰‡å¤±æ•—ï¼š{e}")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # å¾ˆå¤šäººæœƒç”¨ã€Œæª”æ¡ˆã€å‚³åœ–ï¼Œé€™è£¡ä¹Ÿæ”¯æ´
    try:
        doc = update.message.document
        if not doc.mime_type or not doc.mime_type.startswith("image/"):
            await update.message.reply_text("è«‹å‚³åœ–ç‰‡æª”ï¼ˆæˆ–ç”¨ç›¸ç°¿ä¸Šå‚³ï¼‰ã€‚")
            return
        file = await doc.get_file()
        b = await file.download_as_bytearray()
        await _process_image_bytes(update, b)
    except Exception as e:
        log.exception("è™•ç† document å¤±æ•—")
        await update.message.reply_text(f"âš ï¸ è®€å–æª”æ¡ˆå¤±æ•—ï¼š{e}")

# ====== å•Ÿå‹• ======
if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("ping", ping))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.Document.IMAGE, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo_text))

    # æ¸…æ‰ç©æ¬ çš„ pending updatesï¼Œé¿å…å¡ä½ & timeout
    app.run_webhook(
        listen="0.0.0.0",
        port=10000,
        webhook_url=WEBHOOK_URL,
        drop_pending_updates=True,
    )
