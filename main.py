import os
import tempfile
import cv2
import numpy as np
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters

# Telegram & Webhook è¨­å®š
BOT_TOKEN = os.environ["BOT_TOKEN"]
WEBHOOK_URL = os.environ["WEBHOOK_URL"]

# OpenAI é‡‘é‘°
openai.api_key = os.environ["OPENAI_API_KEY"]

# ä½¿ç”¨è€…é æ¸¬è¨˜æ†¶
user_last_prediction = {}

# å•Ÿå‹•æŒ‡ä»¤
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ä½ å¥½ï¼Œæˆ‘æ˜¯ç™¾å®¶æ¨‚é æ¸¬æ©Ÿå™¨äººï¼ˆGPT ç‰ˆï¼‰ï¼è«‹å‚³ç‰Œè·¯åœ–ç‰‡çµ¦æˆ‘åˆ†æã€‚")

# è§£æåœ–ç‰‡ç‚ºèŠ/é–’
def analyze_baccarat_image(image_path: str, cell_size=30):
    image = cv2.imread(image_path)
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    lower_red1 = np.array([0, 100, 100])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 100, 100])
    upper_red2 = np.array([179, 255, 255])
    lower_blue = np.array([100, 150, 0])
    upper_blue = np.array([140, 255, 255])
    lower_green = np.array([40, 40, 40])
    upper_green = np.array([90, 255, 255])

    red_mask = cv2.inRange(hsv, lower_red1, upper_red1) + cv2.inRange(hsv, lower_red2, upper_red2)
    blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
    green_mask = cv2.inRange(hsv, lower_green, upper_green)

    contours_red = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    contours_blue = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
    contours_green = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]

    points = []

    def process_contours(contours, label):
        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            col = x // cell_size
            row = y // cell_size
            points.append((label, col, row))

    process_contours(contours_red, 'èŠ')
    process_contours(contours_blue, 'é–’')
    process_contours(contours_green, 'å’Œ')

    max_col = max([p[1] for p in points], default=0) + 1
    max_row = max([p[2] for p in points], default=0) + 1
    grid = [['' for _ in range(max_col)] for _ in range(max_row)]

    for label, col, row in points:
        grid[row][col] = label

    columns = []
    for col in range(max_col):
        column = []
        for row in range(max_row):
            if grid[row][col]:
                column.append(grid[row][col])
        if column:
            columns.append(column)

    return [x for col in columns for x in col if x in ["èŠ", "é–’"]]

# GPT æ¨¡å‹é æ¸¬é‚è¼¯
def ask_gpt_prediction(history_list):
    prompt = (
        f"ä½ æ˜¯ç™¾å®¶æ¨‚èµ°å‹¢åˆ†æå¸«ï¼Œæ ¹æ“šä»¥ä¸‹èŠé–’ç´€éŒ„åˆ¤æ–·ä¸‹ä¸€é¡†å¯èƒ½å‡ºç¾çš„æ˜¯ã€ŒèŠã€æˆ–ã€Œé–’ã€ã€‚\n\n"
        f"ç‰Œè·¯ç´€éŒ„ï¼š{history_list}\n\n"
        f"è«‹æ ¹æ“šè¶¨å‹¢ã€é€£çºŒã€åå½ˆç­‰ç‰¹æ€§ï¼Œåšå‡ºé æ¸¬ï¼Œå›è¦†æ ¼å¼å¦‚ä¸‹ï¼š\n"
        f"âœ… é æ¸¬ï¼šèŠ\n"
        f"ğŸ“Š å‹ç‡ï¼šèŠ 52.0%ã€é–’ 48.0%\n"
        f"ğŸ§  çµ±åˆåˆ†æï¼šæ ¹æ“šè¿‘æœŸèŠæ–¹é€£çºŒæ€§èˆ‡å‰¯è·¯ç´…åï¼Œé æ¸¬èŠæ–¹çºŒå‹¢ã€‚\n\n"
        f"è«‹ç”¨é¡ä¼¼æ ¼å¼å›è¦†ï¼š"
    )

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„ç™¾å®¶æ¨‚è¶¨å‹¢é æ¸¬åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        reply = response.choices[0].message.content.strip()
        return reply
    except Exception as e:
        return f"âš ï¸ GPT åˆ†æå¤±æ•—ï¼š{e}"

# åœ–ç‰‡è™•ç†ä¸»æµç¨‹
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ“¸ åœ–ç‰‡å·²æ¥æ”¶ï¼Œé–‹å§‹åˆ†æ...")

    user_id = update.message.from_user.id

    photo_file = await update.message.photo[-1].get_file()
    image_bytes = await photo_file.download_as_bytearray()

    with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_image:
        temp_image.write(image_bytes)
        temp_path = temp_image.name

    try:
        history = analyze_baccarat_image(temp_path)

        if len(history) < 5:
            await update.message.reply_text("âš ï¸ è³‡æ–™å¤ªå°‘ç„¡æ³•åˆ†æï¼Œè«‹æä¾›æ›´å¤šç‰Œè·¯åœ–ç‰‡ã€‚")
            return

        gpt_reply = ask_gpt_prediction(history)
        await update.message.reply_text(gpt_reply)

        if "èŠ" in gpt_reply and "é æ¸¬ï¼šèŠ" in gpt_reply:
            user_last_prediction[user_id] = "èŠ"
        elif "é–’" in gpt_reply and "é æ¸¬ï¼šé–’" in gpt_reply:
            user_last_prediction[user_id] = "é–’"
        else:
            user_last_prediction[user_id] = None

    except Exception as e:
        await update.message.reply_text(f"âš ï¸ åˆ†æéŒ¯èª¤ï¼š{e}")

# å›å ±å¯¦éš›çµæœå­¸ç¿’
async def handle_result(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    args = context.args

    if not args or args[0] not in ["èŠ", "é–’"]:
        await update.message.reply_text("è«‹ä½¿ç”¨æ ¼å¼ï¼š/result èŠ æˆ– /result é–’")
        return

    actual = args[0]
    predicted = user_last_prediction.get(user_id)

    if not predicted:
        await update.message.reply_text("âš ï¸ å°šæœªæœ‰é æ¸¬ç´€éŒ„ï¼Œè«‹å…ˆå‚³åœ–ç‰‡åˆ†æã€‚")
        return

    if actual == predicted:
        await update.message.reply_text("âœ… é æ¸¬æ­£ç¢ºï¼Œå·²è¨˜éŒ„é€™æ¬¡æˆåŠŸï¼")
    else:
        await update.message.reply_text("âŒ é æ¸¬éŒ¯èª¤ï¼Œä¸‹æ¬¡å†åŠªåŠ›ï¼")

    user_last_prediction.pop(user_id)

# å»ºç«‹æ©Ÿå™¨äººæ‡‰ç”¨
app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(CommandHandler("result", handle_result))
app.add_handler(MessageHandler(filters.PHOTO, handle_photo))

# å•Ÿå‹• Webhook
app.run_webhook(
    listen="0.0.0.0",
    port=10000,
    webhook_url=WEBHOOK_URL
)
